\chapter{Опис створеного пз}
\label{sec:software}
Як було зазначено в підрозділі~\ref{sec:my-panoram}, в рамках проведених робіт було розроблено систему, що представляє собою ПЗ, ціллю якого є побудова зображень, що емулюють фотографії, отримані камерами з широкими кутами огляду (панорамними). 


\section{Вихідні передумови та вимоги}

Передумовою для створення такої системи є суттєва потреба у аналогічних інструментах в відеозаписуючій індустрії. Сфери і потреби, для застосовується панорамне зображення різняться дуже широко, і можуть бути як естетичними - панорамні зйомки пейзажів, так і технічні - об'єднання зображень з кількох камер спостереження для полегшення трекінгу об'єктів, що видно на декількох зображеннях. 

На сьогоднішній день уже є розроблені засоби для об'єднання серій статичних зображень в панорами~\cite{Brown:2007fk}, однак, найчастіше ці засоби або розраховані на професійне використання, а отже мають невиправдану ціну, або є продуктами з відкритим вихідним кодом, тобто підтримуються ентузіастами, або науковцями, а тому якість таких засобів найчастіше стає перепоною для користувача. 

Головною відмінністю розробленого засобу від існуючих є можливість обробки не тільки наборів статичних зображень, а і динамічних відеопотоків. Варто зазначити, що обробка відеопотоків вібувається не просто, як послідовність обробки незалежних зображень, а з використанням динамічної інформації про зображення та його зміну з плином часу.

\section{Використана платформа та інструменти}

При розробці ПЗ було прийняте рішення, за можливістю, базувати кінцевий продукт на наборі вільних інструментів, тобто відкритих, або тих, що мають безкоштовну ліцензію. Тому до списку основних використаних інструментів було включено: середовище розробки XCode, текстовий редактор Vim, компілятори мови C++: GCC та LLVM, дебагери GDB та LLDB, бібліотеку комп'ютерного зору OpenCV, систему контролю версій Mercurial. Для розробки було використано ОС Mac OS X, але отриманий в результаті код є легко переносимим на інші ОС, завдяки використаним інструментам. 

\subsection{Середовище розробки XCode}
Середовище XCode (\url{http://developer.apple.com/tools/xcode/}), розроблене компанією Apple, є універсальним засобом для розробки ПЗ для різноманітних платформ, як серверних та десктопних, так і мобільних. Важливими перевагами XCode є якісна підтримка використовуваної ОС Mac OS X, текстовий редактор з інтерактивною підтримкою створення С++ коду, інтеграція з допоміжними інструментами, такими як:компілятор LLVM, системи контролю версій, дебагер GDB, або LLDB та ін. 

Приклад застосування середовища XCode зображено на рисунку~\ref{fig:xcode}

\coolfigure{xcode}{Приклад застосування середовища XCode}{fig:xcode}

\subsection{OpenCV}
\label{sec:opencv}
OpenCV (з англ. Open Source Computer Vision Library, бібліотека комп'ютерного зору з відкритим вихідним кодом, \url{http://opencv.willowgarage.com/}) — бібліотека алгоритмів комп'ютерного зору, обробки зображень та чисельних алгоритмів загального призначення з відкритим вихідним кодом. Реалізована на C/C++, також розробляється для Python, Ruby, Matlab, Lua та інших мов. Розповсюджується на умовах ліцензії BSD. Започаткована в 1999 році в Intel Research з метою створення стандартної інфраструктури для розробників алгоритмів і методів комп'ютерного зору.

Включає модулі для обробки зображень, калібрування камер, створення інтерфейсів користувача, машинного навчання, обробки відео зі стереокамер та ін.

На сьогоднішній день використовується по всьому світу для:

\begin{itemize}
    \item набори для визначення 2D та 3D ключових точок;
    \item оцінка переміщення камери;
    \item системи розпізнання обличчя;
    \item розпізнання жестів;
    \item взаємодія людини з комп'ютером;
    \item мобільна робототехніка;
    \item аналіз руху;
    \item ідентифікація об'єктів;
    \item сегментація та розпізнавання;
    \item стереоскопічна обробка зображень: визначення глибини за двома камерами;
    \item відновлення 3D структури;
    \item трекінг руху.
\end{itemize}

\subsection{Mercurial}
Mercurial — кросплатформенна розподілена система керування версіями, що була розроблена для ефективної роботи з дуже великими репозиторіями коду. Система Mercurial написана на Python, хоча чутливі до швидкодії частини реалізовані у вигляді Python-розширень на C. Репозиторії Mercurial керуються за допомогою утиліти для командного рядка hg. Ця утиліта має компактний інтерфейс, і тому Mercurial вважається більш простою системою для ознайомлення, ніж, наприклад git.

\section{Опис структури ПЗ}

Загальну структуру розробленої системи наведено на рис~\ref{fig:diplom-soft-modules}. Система складається з наступних модулів:

\begin{enumerate}
  \item Модуль введення даних.
  \item Загальний модуль пошуку ключових точок, що розширюється конкретними реалізаціями алгоритмів: SURF, SIFT, ASIFT.
  \item Модуль пошуку співпадінь.
  \item Модуль визначення геометричного перетворення між зображеннями та застосування його до вхідних даних.
  \item Модуль інтерфейсу користувача, що виконує виведення отриманих результатів на екран та у файл.
\end{enumerate}

\coolfigure{diplom-soft-modules}{Загальна структура розробленого ПЗ}{fig:diplom-soft-modules}

Кожен модуль виконує свої функції, але всі вони задіяні у спільному потоці даних. Діаграму потоків даних наведено на рисунку~\ref{fig:diplom-soft-dfd}. 

\coolfigure{diplom-soft-dfd}{Діаграма потоків даних}{fig:diplom-soft-dfd}

При побудові системи було приділено увагу її дизайну та архітектурі, тому для організації її функціональних та структурних частин було застосовано принципи ООП. Було широко застосовано патерн проектування ``стратегія'' з метою абстрагування основного алгоритму роботи програми від конкретних методів отримання ключових точок та їх співставлення. 

Для роботи програми було реалізовано набір класів, що зображено на відповідній діаграмі (рис.~\ref{fig:diplom-soft-classes}). 

\coolfigure{diplom-soft-classes}{Діаграма класів}{fig:diplom-soft-classes}

\section{Алгоритм роботи системи}

Весь процес роботи системи можна умовно розділити на декілька частин, кожна з яких відрізняється своїми особливостями: потреба у взаємодії з користувачем, підвищені вимоги до обчислювальних ресурсів, можливість розпаралелювання задач та ін. 

Алгоритм складається з наступних кроків:

\begin{enumerate}
  \item Визначення вхідних даних.
  \item Ініціалізація службових даних.
  \item Введення та конвертація вхідних даних.
  \item Якщо можливо - отримання нових поточних зображень з вхідних даних. Інакше - до п. 13.
  \item Конвертація отриманих зображень у необхідний формат.
  \item Обчислення ключових точок та дескрипторів для нових отриманих зображень.
  \item Пошук відповідностей між ключовими точками.
  \item Обчислення геометричного перетворення між поточними зображеннями.
  \item Покращення геометричного перетворення.
  \item Застосування геометричного перетворення до поточних зображень.
  \item Обчислення числових характеристик.
  \item Виведення поточних результатів. До п. 4.
  \item Виведення загальних результатів.
  \item Завершення роботи.
\end{enumerate}

\subsection{Визначення вхідних даних}
В побудованій системі вхідні дані визначаються наступними параметрами:

\begin{itemize}
  \item ім'я першого вхідного файлу;
  \item кількість кадрів, що необхідно пропустити и першому файлі;
  \item ім'я другого вхідного файлу;
  \item кількість кадрів, що необхідно пропустити и другому файлі;
  \item флаг режиму порівняння послідовних кадрів.
\end{itemize}

Іменем вхідного файлу може бути рядок із повним шляхом до файлу з зображенням, або відео, або рядок з ключовим словом ``CAM''. Якщо вказане ключове слово ``CAM'', то замість вхідного файлу, у якості джерела даних буде використано під'єднану до комп'ютера відео-камеру. При цьому використовується клас cv\dotsVideoCapture бібліотеки OpenCV, описаної в~ref{sec:opencv}.

Параметри, що описують кількість кадрів, що необхідно пропустити є суттєвими при необхідності синхронізувати відоепотоки, в яких присутній зсув у часі. Так, наприклад, якщо запис першого відео було розпочато о 13:15:00, а другого - о 13:15:03, то враховуючи, що швидкість кадрів у кожному з відео дорівнює 30, можна вважати, що якщо перше відео буде оброблятися, починаючи з 90-го кадру, то буде отримано кращу синхронізацію в часі між подіями, зображуваними на відео. Крім того, пропускання кадрів корисне у випадках, коли частина відеопотоку, що нас цікавить починається не з початком відео, а лише через деякий час, наприклад після вступу, заставки, чи зображення деякого режиму очікування. 

\subsection{Ініціалізація службових даних}

Після визначення та ініціалізації вхідних даних, програма виконує ініціалізацію службових даних, а саме віділяє пам'ять для оброблюваних зображень, сховища для наборів даних, таких як ключові точки, та пари точок, що співпадають та інше. Також на етапі ініціалізації вхдних даних визначаються розміри та положення вікна інтерфейсу користувача, разом з положеннями окремих елементів інтерфейсу всередині цього вікна. Цю функціональність можна коротко описати наступним програмним кодом:

\lstset{language=C++}
\begin{lstlisting}
void layout(cv::Mat& outputImage, const cv::Size& src_size,
            const cv::Size& reference_size, cv::Mat& output_src_image,
            cv::Mat& output_ref_image, cv::Mat& output_stitched_img,
            cv::Mat& output_info_img) {
    cv::Rect roi;
    
    // min size for info
    cv::Size info(300, 100);
    
    cv::Size stitched_size(src_size.width * 2, src_size.height);
    
    outputImage.create(cv::Size(src_size.width + stitched_size.width,
                                max(src_size.height + reference_size.height,
                                    stitched_size.height + info.height)),
                       CV_8UC3);
    output_src_image = outputImage(cv::Range(0, src_size.height),
                                   cv::Range(0, src_size.width));
    output_ref_image = outputImage(cv::Range(src_size.height,
                                             src_size.height + 
                                                reference_size.height),
                                   cv::Range(0, reference_size.width));
    
    roi = cv::Rect(src_size.width, 0, 
                   stitched_size.width, stitched_size.height);
    output_stitched_img = outputImage(roi);
    
    roi = cv::Rect(src_size.width, stitched_size.height,
                   stitched_size.width,
                   src_size.height + reference_size.height -
                                                stitched_size.height);
    output_info_img = outputImage(roi);    
}

\end{lstlisting}

В результаті готується вікно зі змістом, зображеним на рис.~\ref{fig:soft-layout}.


\coolfigure{diplom-soft-layout}{Струтурні елементи вікна інтерфейсу користувача}{fig:soft-layout}

\subsection{Введення та конвертація вхідних даних.}
За даними, визначеними на першому кроці конструюються об'єкти, що дозволяють працювати з будь-яким типом вхідних даних за допомогою спільного інтерфейсу. Загальні вимоги до інтерфейсу взаємодії включають необхідність визначення наступних методів:

\begin{itemize}
  \item отримання наступного кадру з джерела, якщо можливо;
  \item отримання параметрів джерела (ширина, висота результуючого зображення).
\end{itemize}
При цьому джерело, що базується на файлі зображення буде поводити себе, як відео з одним кадром, а зображення з відео-камери буде мати нескінченну кількість кадрів. 

\subsection{Отримання нових поточних зображень з вхідних даних}
Проводиться спроба з кожного, визначеного в п. 1 джерела отримати новий кадр. У випадку, коли жодне з джерел не може надати нового кадру, програма завершую роботу. Якщо хоча б одне з джерел надає нові дані, то для всіх інших джерел, що вже вичерпані використовується останнє з отриманих з них зображення. 

Таким чином, користувачу надається можливість проводити досліди, порівнюючи, як набори відео, так і задані відео з фото, або, навіть, фото з зображеннями, отриманими з відеокамери в реальному часі. 

\subsection{Конвертація отриманих зображень у необхідний формат}
Усі досліджувані алгоритми базуються на роботі з зображеннями, дані в яких зберігаються в одному каналі, розміром 8 біт на один піксель. 

В ході роботи було прийняте рішення для подачі даних на вхід досліджуваним алгоритмам використовувати єдиний канал, тому до отриманих на попередньому кроцы зображень було застосовано перетворення з трьохканальних зображень на одноканальне зображення в градаціях сірого. Приклад конвертації зображення з кольорового простору RGB до градацій сірого шляхом змішування каналів зображено на рис.~\ref{fig:rgb-grayscale}

\coolwfigure{rgb_channels}{Приклад поканальної конвертації з RGB у градації сірого}{fig:rgb-grayscale}{0.5\linewidth}

Крім того, в залежності від обладнання, що використовується для отримання фото, або відео може бути застосована додаткова згладжуюча фільтрація для подолання шуму пристроїв. 

\section{Обчислення ключових точок та дескрипторів для нових отриманих зображень}

До сірих зображень застосовується один із досліджуваних алгоритмів. В результаті отримується набір ключових точок з відповідними їм параметрами: координатами на досліджуваному зображенні, розміром та орієнтацією ключових точок. Приклад накладання даних про ключові точки зображено на рис.~\ref{fig:keypoints-sample}.

\coolwfigure{sift-keypoints}{Приклад накладання даних про ключові точки на зображення}{fig:keypoints-sample}{0.5\linewidth}

Крім того, для кожної знайденої точки обчислюється так званий дескриптор, що є багатовимірним числовим вектором та описує ключову точку в деякій степені інваріантно, відносно її позиції та оточення. 

\subsection{Пошук відповідностей між ключовими точками}
До обчислених дескрипторів ключових точок, знайдених на попередньому кроці, застосовується деякий алгоритм пошуку найближчих сусідів, що дозволяє для кожної точки $K_{1i}$ з множини знайдених на одному з зображень, знайти найближчу за відстанню у просторі дескрипторів точку з множини точок $K_{2\cdot}$ другого зображення (\ref{eq:nearest-neighbour}). Результатом даного кроку є набір пар ключових точок $M$ таких, що:

\begin{equation}
\label{eq:nearest-neighbour}
M = \{(K_{1i}, K_{2j}) | K_{2j} = argmin_k{\|K_{2k} - K_{1i}\|}, K_{1i} \in K_1\},
\end{equation}

де $K1$ та $K2$ - відповідно ключові точки, знайдені на першому і другому зображеннях, а $\|K_p - K_q\|$ - відстань між дескрипторами заданих ключових точок.

\section{Обчислення геометричного перетворення між поточними зображеннями}
Маючи пари відповідних точок з попереднього кроку, можна оцінити геометричне перетворення між досліджуваними зображеннями. В найпростішому випадку для цього може бути достатньо чотирьох пар відповідних точок, але для збільшення стійкості та ефективності пошуку такого перетворення використовують усю доступну множину пар відповідностей. В результаті цього кроку отримують матрицю проекитвного перетворення розмірності $3\times3$, яка є оцінкою матриці геометричного перетворення між зображеннями, отриманими в п. 4, а саме:

\begin{equation}
  s_i \begin{bmatrix}x'_i \\ y'_i \\ 1\end{bmatrix} \sim H \begin{bmatrix} x_i \\ y_i \\ 1\end{bmatrix},
\end{equation}

такою, що мінімізує помилку зворотної проекції:

\begin{equation}
\sum _i \left ( x'_i- \frac{h_{11} x_i + h_{12} y_i + h_{13}}{h_{31} x_i + h_{32} y_i + h_{33}} \right )^2
  + 
        \left ( y'_i- \frac{h_{21} x_i + h_{22} y_i + h_{23}}{h_{31} x_i + h_{32} y_i + h_{33}} \right )^2 
\end{equation}

\section{Покращення геометричного перетворення}
Отримане на попередньому кроці проективне перетворення може демонструвати суттєві відхилення від реальної величини з наступних причин:

\begin{itemize}
  \item зашумленість зображень може спричинити спотворення в побудованих дескрипторах, а отже і невірну роботу алгоритму RANSAC;
  \item сам алгоритм RANSAC є недетрмінованим алгоритмом, а отже схильний до випадкових помилок.
\end{itemize}

У зв'язку з цим до алгоритму роботи програми було додано додатковий крок, призначений для збільшення стійкості до випадкових збурень, що можуть бути отримані в процесі обробки даних на попередніх кроках. 
Для розв'язку цієї задачі було використано усереднюючий фільтр. Даний фільтр працює за принципом ковзного середнього з деяким наперед заданим розміром вікна $N$. Тобто, замість обчисленої на попередньому кроці матриці перетворення $H_i$ було використано фільтроване значення $\bar{H_i}$ обчислене за формулою:

\begin{equation}
  \label{eq:mean-homo}
  \bar{H_i} = \frac{1}{N_i} \sum_{k=\min(0,i-w+1), i}{I_i H_i},
\end{equation}

де $w$ - розмір вікна фільтрації, а $I_i = \begin{cases} 1 & \text{, якщо $H_i \neq 0$} \\ 0 & \text{інакше}\end{cases} $ - індикатор ненульової матриці.

\subsection{Застосування геометричного перетворення до поточних зображень}

Обчислене на попередньому кроці геометричне перетворення застосовується до одного із вхідних зображень $src$, тобто будується нове зображення $dst$, таке, що:

\begin{equation}
  \texttt{dst} (x,y) =  \texttt{src} \left ( \frac{H_{11} x + H_{12} y + H_{13}}{H_{31} x + H_{32} y + H_{33}} ,     \frac{H_{21} x + H_{22} y + H_{23}}{H_{31} x + H_{32} y + H_{33}} \right ).
\end{equation}

Після додавання до результуючого зображення другого вхідного, отримаємо результуюче зображення, що включає одне з вихідних зображень без змін та додане друге вхідне зображення з компенсованим проективним перетворенням. 

\subsection{Обчислення числових характеристик та виведення результатів}

Після власне проведення операцій з даними поточних зображень, отримані числові характеристики, такі як: кількості знайдених точок, співпадінь, значення матриць перетворення виводяться на екран та заносяться до файлу журналу для подальшого аналізу.

На цьому ж етапі формується зображення інтерфейсу користувача, на якому наведено (в залежності від настройок) набір вхідних зображень, знайдені ключові точки їх співпадіння на вхідних зображеннях, вихідне зображення.

Після цього кроку ітерації повертаються до пункту 4, тобто вибираються нові поточні кадри та аналіз повторюється.

\subsection{Завершення роботи}

Після того, як останні кадри кожного з використаних джерел вичерпані, або у випадку відповідної команди користувача програма переходить у режим завершення роботи. 

При цьому звільняються ресурси, що були зайняті програмою, закриваються файли, що використовувалися для запису журналів та знищується інтерфейс користувача.

\section{Демонстрація роботи}

Приклад обробки двох паралельних відеопотоків для побудови об'єднаного відеозображення показано на рис.~\ref{fig:soft-sample}.

\coolfigure{soft-sample}{Приклад роботи програмної частини розробленої системи}{fig:soft-sample}

\section{Висновки до розділу \ref{sec:software}}

Підсумовуючи вищезазначене, в ході виконання роботи було створено програмний засіб, що було використано для порівняння та аналізу результатів, отриманих з застосуванням запропонованого методу покращення обробки цифрових відеозображень. 

При розробці ПЗ було застосовано структурний підхід, було підготовлено набір проектної документації складено алгоритми, та власне створено вихідні коди. 

Слід зазначити, що при побудові ПЗ було використано виключно вільні та безкоштовні інструменти, що є важливим фактом для подальшого використання отриманих результатів.
